{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn as nn\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from utility import img_transform, EmbeddingHead\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/pblock-32965-idx_280x175\"\n",
    "NUM_TRAIN = 6593 # 20%\n",
    "NUM_TEST = 26372 # 80%\n",
    "NUM_TOTAL = 35912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pallet_id</th>\n",
       "      <th>path</th>\n",
       "      <th>camera</th>\n",
       "      <th>frame</th>\n",
       "      <th>target</th>\n",
       "      <th>frame_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001000000000002948</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001000000000002948</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>1</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001000000000002948</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>2</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001000000000002948</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>2</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001000000000002949</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>1</td>\n",
       "      <td>1234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pallet_id                                               path  \\\n",
       "0  1001000000000002948  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "1  1001000000000002948  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "2  1001000000000002948  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "3  1001000000000002948  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "4  1001000000000002949  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "\n",
       "   camera  frame  target  frame_rel  \n",
       "0       1   1009       0          0  \n",
       "1       1   1012       0          1  \n",
       "2       2   1007       0          0  \n",
       "3       2   1010       0          1  \n",
       "4       1   1234       1          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"metadata.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PalletTupleDataset():\n",
    "    def __init__(self, data, target, transform=None, target_transform=None):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)-1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 2 == 0:\n",
    "            # genuine pair\n",
    "            idx_one = idx\n",
    "            idx_two = idx+1\n",
    "            label = 0\n",
    "        else:\n",
    "            # impostor pair\n",
    "            idx_one = idx\n",
    "            idx_list = list(range(len(self.data)))\n",
    "            idx_list.remove(idx)\n",
    "            idx_list.remove(idx+1)\n",
    "            idx_list.remove(idx-1)\n",
    "            idx_two = np.random.choice(idx_list)\n",
    "            label = 1\n",
    "\n",
    "        img_one = Image.open(self.data[idx_one]).convert('RGB')\n",
    "        img_two = Image.open(self.data[idx_two]).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img_one = self.transform(img_one)\n",
    "            img_two = self.transform(img_two)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return img_one, img_two, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PalletDataset():\n",
    "    def __init__(self, data, target, transform=None, target_transform=None):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx]).convert('RGB')\n",
    "        label = self.target[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selector = (df[\"target\"] < NUM_TRAIN)\n",
    "trainset = PalletTupleDataset(df.loc[train_selector, \"path\"].values, df.loc[train_selector, \"target\"].values, transform=img_transform, target_transform=lambda x: torch.tensor(x, dtype=torch.long))\n",
    "trainevalset = PalletDataset(df.loc[train_selector, \"path\"].values, df.loc[train_selector, \"target\"].values, transform=lambda x: img_transform(x, is_eval=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=8)\n",
    "trainevalloader = torch.utils.data.DataLoader(trainevalset, batch_size=128, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_energy(emb1, emb2):\n",
    "    return torch.sum(torch.abs(emb1 - emb2), dim=1)\n",
    "    #return torch.sqrt(torch.sum(torch.pow(emb1-emb2, 2), dim=1))\n",
    "\n",
    "def criterion(energy, labels):\n",
    "  Q = np.sqrt(2048)\n",
    "  #Q = 2\n",
    "  result = (1 - labels) * (2/Q) * energy**2 + labels * 2 * Q * torch.exp(-2.77/Q * energy)\n",
    "  return torch.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nils/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "net.fc = EmbeddingHead()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[20, 40], gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 8.96572\n",
      "[1,   400] loss: 7.83560\n",
      "[1,   600] loss: 7.43859\n",
      "[1,   800] loss: 7.25818\n",
      "[2,   200] loss: 7.09279\n",
      "[2,   400] loss: 7.04176\n",
      "[2,   600] loss: 6.82981\n",
      "[2,   800] loss: 6.92160\n",
      "[3,   200] loss: 6.80908\n",
      "[3,   400] loss: 6.73568\n",
      "[3,   600] loss: 6.69473\n",
      "[3,   800] loss: 6.68413\n",
      "[4,   200] loss: 6.73638\n",
      "[4,   400] loss: 6.83117\n",
      "[4,   600] loss: 6.50616\n",
      "[4,   800] loss: 6.66442\n",
      "[5,   200] loss: 6.60479\n",
      "[5,   400] loss: 6.60484\n",
      "[5,   600] loss: 6.64086\n",
      "[5,   800] loss: 6.59295\n",
      "[6,   200] loss: 6.39964\n",
      "[6,   400] loss: 6.62460\n",
      "[6,   600] loss: 6.57419\n",
      "[6,   800] loss: 6.42573\n",
      "[7,   200] loss: 6.34897\n",
      "[7,   400] loss: 6.32949\n",
      "[7,   600] loss: 6.43521\n",
      "[7,   800] loss: 6.48019\n",
      "[8,   200] loss: 6.60736\n",
      "[8,   400] loss: 6.63190\n",
      "[8,   600] loss: 6.31328\n",
      "[8,   800] loss: 6.35557\n",
      "[9,   200] loss: 6.55708\n",
      "[9,   400] loss: 6.28086\n",
      "[9,   600] loss: 6.29948\n",
      "[9,   800] loss: 6.39912\n",
      "[10,   200] loss: 6.38498\n",
      "[10,   400] loss: 6.36781\n",
      "[10,   600] loss: 6.30054\n",
      "[10,   800] loss: 6.28352\n",
      "[11,   200] loss: 6.20184\n",
      "[11,   400] loss: 6.24416\n",
      "[11,   600] loss: 6.39244\n",
      "[11,   800] loss: 6.28203\n",
      "[12,   200] loss: 6.33795\n",
      "[12,   400] loss: 6.28839\n",
      "[12,   600] loss: 6.24696\n",
      "[12,   800] loss: 6.40228\n",
      "[13,   200] loss: 6.31471\n",
      "[13,   400] loss: 6.26561\n",
      "[13,   600] loss: 6.24736\n",
      "[13,   800] loss: 6.24134\n",
      "[14,   200] loss: 6.25708\n",
      "[14,   400] loss: 6.28540\n",
      "[14,   600] loss: 6.11031\n",
      "[14,   800] loss: 6.20643\n",
      "[15,   200] loss: 6.26613\n",
      "[15,   400] loss: 6.11777\n",
      "[15,   600] loss: 6.19135\n",
      "[15,   800] loss: 6.19474\n",
      "[16,   200] loss: 5.91352\n",
      "[16,   400] loss: 5.99259\n",
      "[16,   600] loss: 6.34940\n",
      "[16,   800] loss: 6.37193\n",
      "[17,   200] loss: 6.13419\n",
      "[17,   400] loss: 5.81541\n",
      "[17,   600] loss: 6.26387\n",
      "[17,   800] loss: 6.00705\n",
      "[18,   200] loss: 6.26813\n",
      "[18,   400] loss: 6.10369\n",
      "[18,   600] loss: 6.14347\n",
      "[18,   800] loss: 6.36874\n",
      "[19,   200] loss: 6.28480\n",
      "[19,   400] loss: 5.94894\n",
      "[19,   600] loss: 6.18884\n",
      "[19,   800] loss: 5.98497\n",
      "[20,   200] loss: 6.16110\n",
      "[20,   400] loss: 6.01538\n",
      "[20,   600] loss: 6.05613\n",
      "[20,   800] loss: 5.96700\n",
      "[21,   200] loss: 5.97747\n",
      "[21,   400] loss: 6.00071\n",
      "[21,   600] loss: 5.94224\n",
      "[21,   800] loss: 6.06712\n",
      "[22,   200] loss: 6.01972\n",
      "[22,   400] loss: 6.11858\n",
      "[22,   600] loss: 6.03681\n",
      "[22,   800] loss: 6.11790\n",
      "[23,   200] loss: 6.21780\n",
      "[23,   400] loss: 6.03089\n",
      "[23,   600] loss: 6.00405\n",
      "[23,   800] loss: 5.95143\n",
      "[24,   200] loss: 6.13359\n",
      "[24,   400] loss: 6.04279\n",
      "[24,   600] loss: 6.09949\n",
      "[24,   800] loss: 6.02734\n",
      "[25,   200] loss: 6.27357\n",
      "[25,   400] loss: 5.93897\n",
      "[25,   600] loss: 5.95503\n",
      "[25,   800] loss: 6.01385\n",
      "[26,   200] loss: 6.22920\n",
      "[26,   400] loss: 6.05995\n",
      "[26,   600] loss: 5.83121\n",
      "[26,   800] loss: 6.07656\n",
      "[27,   200] loss: 6.05372\n",
      "[27,   400] loss: 6.01186\n",
      "[27,   600] loss: 6.01029\n",
      "[27,   800] loss: 5.84478\n",
      "[28,   200] loss: 6.07368\n",
      "[28,   400] loss: 6.07202\n",
      "[28,   600] loss: 5.85241\n",
      "[28,   800] loss: 5.86437\n",
      "[29,   200] loss: 6.15013\n",
      "[29,   400] loss: 5.95751\n",
      "[29,   600] loss: 6.09170\n",
      "[29,   800] loss: 5.98781\n",
      "[30,   200] loss: 6.00025\n",
      "[30,   400] loss: 6.02598\n",
      "[30,   600] loss: 5.96928\n",
      "[30,   800] loss: 5.98090\n",
      "[31,   200] loss: 6.15035\n",
      "[31,   400] loss: 6.19037\n",
      "[31,   600] loss: 5.82155\n",
      "[31,   800] loss: 5.91864\n",
      "[32,   200] loss: 5.92921\n",
      "[32,   400] loss: 5.89466\n",
      "[32,   600] loss: 5.96621\n",
      "[32,   800] loss: 6.00189\n",
      "[33,   200] loss: 5.83476\n",
      "[33,   400] loss: 6.03918\n",
      "[33,   600] loss: 5.95384\n",
      "[33,   800] loss: 5.96275\n",
      "[34,   200] loss: 5.94570\n",
      "[34,   400] loss: 5.89705\n",
      "[34,   600] loss: 5.81373\n",
      "[34,   800] loss: 5.93458\n",
      "[35,   200] loss: 5.89135\n",
      "[35,   400] loss: 5.93295\n",
      "[35,   600] loss: 5.87319\n",
      "[35,   800] loss: 6.01155\n",
      "[36,   200] loss: 5.95364\n",
      "[36,   400] loss: 5.84824\n",
      "[36,   600] loss: 5.94853\n",
      "[36,   800] loss: 5.79310\n",
      "[37,   200] loss: 5.94046\n",
      "[37,   400] loss: 5.89809\n",
      "[37,   600] loss: 5.77157\n",
      "[37,   800] loss: 5.94696\n",
      "[38,   200] loss: 5.78216\n",
      "[38,   400] loss: 5.86309\n",
      "[38,   600] loss: 5.88655\n",
      "[38,   800] loss: 5.87717\n",
      "[39,   200] loss: 5.81728\n",
      "[39,   400] loss: 5.93530\n",
      "[39,   600] loss: 5.88021\n",
      "[39,   800] loss: 5.87494\n",
      "[40,   200] loss: 5.80124\n",
      "[40,   400] loss: 5.78739\n",
      "[40,   600] loss: 5.87704\n",
      "[40,   800] loss: 5.93999\n",
      "[41,   200] loss: 5.76929\n",
      "[41,   400] loss: 5.70534\n",
      "[41,   600] loss: 5.83301\n",
      "[41,   800] loss: 5.98952\n",
      "[42,   200] loss: 5.85543\n",
      "[42,   400] loss: 5.81720\n",
      "[42,   600] loss: 5.88947\n",
      "[42,   800] loss: 5.85500\n",
      "[43,   200] loss: 5.89767\n",
      "[43,   400] loss: 5.78395\n",
      "[43,   600] loss: 5.77658\n",
      "[43,   800] loss: 5.69307\n",
      "[44,   200] loss: 6.04589\n",
      "[44,   400] loss: 5.73215\n",
      "[44,   600] loss: 5.82030\n",
      "[44,   800] loss: 5.81639\n",
      "[45,   200] loss: 5.78422\n",
      "[45,   400] loss: 5.91858\n",
      "[45,   600] loss: 5.87490\n",
      "[45,   800] loss: 5.79349\n",
      "[46,   200] loss: 5.82904\n",
      "[46,   400] loss: 5.82712\n",
      "[46,   600] loss: 5.82711\n",
      "[46,   800] loss: 5.79709\n",
      "[47,   200] loss: 5.85006\n",
      "[47,   400] loss: 5.72502\n",
      "[47,   600] loss: 5.89395\n",
      "[47,   800] loss: 5.85469\n",
      "[48,   200] loss: 5.72927\n",
      "[48,   400] loss: 5.81136\n",
      "[48,   600] loss: 5.90856\n",
      "[48,   800] loss: 5.66960\n",
      "[49,   200] loss: 5.77490\n",
      "[49,   400] loss: 5.84882\n",
      "[49,   600] loss: 5.81721\n",
      "[49,   800] loss: 5.64215\n",
      "[50,   200] loss: 6.00698\n",
      "[50,   400] loss: 5.72492\n",
      "[50,   600] loss: 5.77201\n",
      "[50,   800] loss: 5.73786\n",
      "[51,   200] loss: 5.93857\n",
      "[51,   400] loss: 5.81933\n",
      "[51,   600] loss: 5.93887\n",
      "[51,   800] loss: 5.86172\n",
      "[52,   200] loss: 5.94172\n",
      "[52,   400] loss: 5.70315\n",
      "[52,   600] loss: 5.76159\n",
      "[52,   800] loss: 5.82309\n",
      "[53,   200] loss: 5.72991\n",
      "[53,   400] loss: 5.75362\n",
      "[53,   600] loss: 5.70708\n",
      "[53,   800] loss: 5.81155\n",
      "[54,   200] loss: 5.80459\n",
      "[54,   400] loss: 5.77086\n",
      "[54,   600] loss: 5.67927\n",
      "[54,   800] loss: 5.83361\n",
      "[55,   200] loss: 5.83877\n",
      "[55,   400] loss: 5.67585\n",
      "[55,   600] loss: 5.78238\n",
      "[55,   800] loss: 5.85297\n",
      "[56,   200] loss: 5.78948\n",
      "[56,   400] loss: 5.70820\n",
      "[56,   600] loss: 5.60778\n",
      "[56,   800] loss: 5.84461\n",
      "[57,   200] loss: 5.87376\n",
      "[57,   400] loss: 5.70135\n",
      "[57,   600] loss: 5.72040\n",
      "[57,   800] loss: 5.80744\n",
      "[58,   200] loss: 5.80723\n",
      "[58,   400] loss: 5.82216\n",
      "[58,   600] loss: 5.78411\n",
      "[58,   800] loss: 5.61065\n",
      "[59,   200] loss: 5.90938\n",
      "[59,   400] loss: 5.80512\n",
      "[59,   600] loss: 5.74336\n",
      "[59,   800] loss: 5.76153\n",
      "[60,   200] loss: 5.80089\n",
      "[60,   400] loss: 5.73564\n",
      "[60,   600] loss: 5.89461\n",
      "[60,   800] loss: 5.75708\n",
      "[61,   200] loss: 5.75096\n",
      "[61,   400] loss: 5.85014\n",
      "[61,   600] loss: 5.66470\n",
      "[61,   800] loss: 5.83882\n",
      "[62,   200] loss: 5.54715\n",
      "[62,   400] loss: 5.61891\n",
      "[62,   600] loss: 5.76070\n",
      "[62,   800] loss: 5.85810\n",
      "[63,   200] loss: 5.75271\n",
      "[63,   400] loss: 5.61819\n",
      "[63,   600] loss: 5.81684\n",
      "[63,   800] loss: 5.71317\n",
      "[64,   200] loss: 5.70379\n",
      "[64,   400] loss: 5.72061\n",
      "[64,   600] loss: 5.63542\n",
      "[64,   800] loss: 5.67854\n",
      "[65,   200] loss: 5.66096\n",
      "[65,   400] loss: 5.76291\n",
      "[65,   600] loss: 5.77362\n",
      "[65,   800] loss: 5.86290\n",
      "[66,   200] loss: 5.57122\n",
      "[66,   400] loss: 5.75478\n",
      "[66,   600] loss: 5.69012\n",
      "[66,   800] loss: 5.58105\n",
      "[67,   200] loss: 5.54654\n",
      "[67,   400] loss: 5.66616\n",
      "[67,   600] loss: 5.72731\n",
      "[67,   800] loss: 5.63019\n",
      "[68,   200] loss: 5.62889\n",
      "[68,   400] loss: 5.74429\n",
      "[68,   600] loss: 5.62350\n",
      "[68,   800] loss: 5.59885\n",
      "[69,   200] loss: 5.62065\n",
      "[69,   400] loss: 5.68134\n",
      "[69,   600] loss: 5.70661\n",
      "[69,   800] loss: 5.59031\n",
      "[70,   200] loss: 5.88421\n",
      "[70,   400] loss: 5.56639\n",
      "[70,   600] loss: 5.56607\n",
      "[70,   800] loss: 5.68251\n",
      "[71,   200] loss: 5.57407\n",
      "[71,   400] loss: 5.56699\n",
      "[71,   600] loss: 5.72377\n",
      "[71,   800] loss: 5.58939\n",
      "[72,   200] loss: 5.93870\n",
      "[72,   400] loss: 5.67525\n",
      "[72,   600] loss: 5.80913\n",
      "[72,   800] loss: 5.45346\n",
      "[73,   200] loss: 5.68221\n",
      "[73,   400] loss: 5.78049\n",
      "[73,   600] loss: 5.72288\n",
      "[73,   800] loss: 5.59163\n",
      "[74,   200] loss: 5.69920\n",
      "[74,   400] loss: 5.59649\n",
      "[74,   600] loss: 5.78495\n",
      "[74,   800] loss: 5.59609\n",
      "[75,   200] loss: 5.53945\n",
      "[75,   400] loss: 5.59698\n",
      "[75,   600] loss: 5.67163\n",
      "[75,   800] loss: 5.59829\n",
      "[76,   200] loss: 5.46404\n",
      "[76,   400] loss: 5.62992\n",
      "[76,   600] loss: 5.63841\n",
      "[76,   800] loss: 5.73751\n",
      "[77,   200] loss: 5.71276\n",
      "[77,   400] loss: 5.57190\n",
      "[77,   600] loss: 5.66740\n",
      "[77,   800] loss: 5.58547\n",
      "[78,   200] loss: 5.59114\n",
      "[78,   400] loss: 5.58784\n",
      "[78,   600] loss: 5.68252\n",
      "[78,   800] loss: 5.71165\n",
      "[79,   200] loss: 5.62554\n",
      "[79,   400] loss: 5.60854\n",
      "[79,   600] loss: 5.62366\n",
      "[79,   800] loss: 5.62173\n",
      "[80,   200] loss: 5.88628\n",
      "[80,   400] loss: 5.66231\n",
      "[80,   600] loss: 5.51352\n",
      "[80,   800] loss: 5.59651\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 80\n",
    "SAVE_PATH = \"model/\"\n",
    "\n",
    "net.to(device)\n",
    "net.train()\n",
    "for epoch in range(80):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        x1, x2, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        out1 = net(x1.to(device))\n",
    "        out2 = net(x2.to(device))\n",
    "        energy = calc_energy(out1, out2)\n",
    "        loss = criterion(energy, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 199:.5f}')\n",
    "            running_loss = 0.0\n",
    "    torch.save(net.state_dict(), os.path.join(SAVE_PATH, \"model_siamese_256x128_\" + str(date.today()) + \".pth\"))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69cf509240d94a37c1094653e766edea7cfd00f05bbee75c76ffbfcae4e4ebc8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('torch_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
