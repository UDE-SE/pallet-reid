{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from utility import img_transform, EmbeddingHead\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/pblock-32965-idx_280x175\"\n",
    "NUM_TRAIN = 6593 # 20%\n",
    "NUM_TEST = 26372 # 80%\n",
    "NUM_TOTAL = 35912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pallet_id</th>\n",
       "      <th>path</th>\n",
       "      <th>camera</th>\n",
       "      <th>frame</th>\n",
       "      <th>target</th>\n",
       "      <th>frame_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001000000000002948</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001000000000002948</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>1</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001000000000002948</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>2</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001000000000002948</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>2</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001000000000002949</td>\n",
       "      <td>/home/nils/Documents/ude/pallet/data/pblock-32...</td>\n",
       "      <td>1</td>\n",
       "      <td>1234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pallet_id                                               path  \\\n",
       "0  1001000000000002948  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "1  1001000000000002948  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "2  1001000000000002948  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "3  1001000000000002948  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "4  1001000000000002949  /home/nils/Documents/ude/pallet/data/pblock-32...   \n",
       "\n",
       "   camera  frame  target  frame_rel  \n",
       "0       1   1009       0          0  \n",
       "1       1   1012       0          1  \n",
       "2       2   1007       0          0  \n",
       "3       2   1010       0          1  \n",
       "4       1   1234       1          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"metadata.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PalletDataset():\n",
    "    def __init__(self, data, target, transform=None, target_transform=None):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx]).convert('RGB')\n",
    "        label = self.target[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset:  26372\n",
      "Trainevalset:  26372\n",
      "Dataset:  131860\n"
     ]
    }
   ],
   "source": [
    "train_selector = (df[\"target\"] < NUM_TRAIN)\n",
    "trainset = PalletDataset(df.loc[train_selector, \"path\"].values, df.loc[train_selector, \"target\"].values, transform=img_transform, target_transform=lambda x: torch.tensor(x, dtype=torch.long))\n",
    "trainevalset = PalletDataset(df.loc[train_selector, \"path\"].values, df.loc[train_selector, \"target\"].values, transform=lambda x: img_transform(x, is_eval=True), target_transform=lambda x: torch.tensor(x, dtype=torch.long))\n",
    "print(\"Trainset: \", len(trainset))\n",
    "print(\"Trainevalset: \", len(trainevalset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nils/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "net = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "net.fc = ClassifierHead(net.fc.in_features, NUM_TRAIN)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[20, 40], gamma=0.3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 200] loss: 8.887 acc: (0.02)\n",
      "[1, 400] loss: 8.889 acc: (0.01)\n",
      "[1, 600] loss: 8.869 acc: (0.02)\n",
      "[1, 800] loss: 8.832 acc: (0.02)\n",
      "[2, 200] loss: 8.624 acc: (0.22)\n",
      "[2, 400] loss: 8.593 acc: (0.27)\n",
      "[2, 600] loss: 8.533 acc: (0.27)\n",
      "[2, 800] loss: 8.466 acc: (0.29)\n",
      "[3, 200] loss: 8.187 acc: (0.73)\n",
      "[3, 400] loss: 8.112 acc: (0.95)\n",
      "[3, 600] loss: 8.041 acc: (1.00)\n",
      "[3, 800] loss: 7.947 acc: (0.97)\n",
      "[4, 200] loss: 7.605 acc: (2.12)\n",
      "[4, 400] loss: 7.536 acc: (2.17)\n",
      "[4, 600] loss: 7.478 acc: (2.23)\n",
      "[4, 800] loss: 7.381 acc: (2.26)\n",
      "[5, 200] loss: 7.006 acc: (4.84)\n",
      "[5, 400] loss: 6.956 acc: (4.81)\n",
      "[5, 600] loss: 6.864 acc: (4.82)\n",
      "[5, 800] loss: 6.800 acc: (4.91)\n",
      "[6, 200] loss: 6.407 acc: (8.41)\n",
      "[6, 400] loss: 6.355 acc: (8.12)\n",
      "[6, 600] loss: 6.304 acc: (8.16)\n",
      "[6, 800] loss: 6.217 acc: (8.36)\n",
      "[7, 200] loss: 5.820 acc: (14.42)\n",
      "[7, 400] loss: 5.797 acc: (13.59)\n",
      "[7, 600] loss: 5.765 acc: (13.45)\n",
      "[7, 800] loss: 5.661 acc: (13.58)\n",
      "[8, 200] loss: 5.289 acc: (19.70)\n",
      "[8, 400] loss: 5.283 acc: (19.04)\n",
      "[8, 600] loss: 5.220 acc: (18.96)\n",
      "[8, 800] loss: 5.157 acc: (19.39)\n",
      "[9, 200] loss: 4.792 acc: (27.17)\n",
      "[9, 400] loss: 4.762 acc: (26.41)\n",
      "[9, 600] loss: 4.746 acc: (26.04)\n",
      "[9, 800] loss: 4.684 acc: (26.15)\n",
      "[10, 200] loss: 4.326 acc: (33.48)\n",
      "[10, 400] loss: 4.286 acc: (32.97)\n",
      "[10, 600] loss: 4.298 acc: (32.59)\n",
      "[10, 800] loss: 4.204 acc: (32.97)\n",
      "[11, 200] loss: 3.842 acc: (41.55)\n",
      "[11, 400] loss: 3.878 acc: (40.24)\n",
      "[11, 600] loss: 3.864 acc: (39.69)\n",
      "[11, 800] loss: 3.811 acc: (39.87)\n",
      "[12, 200] loss: 3.446 acc: (48.22)\n",
      "[12, 400] loss: 3.480 acc: (46.70)\n",
      "[12, 600] loss: 3.460 acc: (46.38)\n",
      "[12, 800] loss: 3.437 acc: (46.36)\n",
      "[13, 200] loss: 3.100 acc: (52.89)\n",
      "[13, 400] loss: 3.123 acc: (51.70)\n",
      "[13, 600] loss: 3.097 acc: (51.24)\n",
      "[13, 800] loss: 3.038 acc: (51.79)\n",
      "[14, 200] loss: 2.737 acc: (59.38)\n",
      "[14, 400] loss: 2.773 acc: (57.77)\n",
      "[14, 600] loss: 2.750 acc: (57.20)\n",
      "[14, 800] loss: 2.732 acc: (57.28)\n",
      "[15, 200] loss: 2.469 acc: (63.45)\n",
      "[15, 400] loss: 2.469 acc: (62.63)\n",
      "[15, 600] loss: 2.442 acc: (62.53)\n",
      "[15, 800] loss: 2.420 acc: (62.83)\n",
      "[16, 200] loss: 2.171 acc: (68.77)\n",
      "[16, 400] loss: 2.191 acc: (67.90)\n",
      "[16, 600] loss: 2.179 acc: (67.42)\n",
      "[16, 800] loss: 2.115 acc: (67.75)\n",
      "[17, 200] loss: 1.919 acc: (73.06)\n",
      "[17, 400] loss: 1.928 acc: (72.21)\n",
      "[17, 600] loss: 1.923 acc: (71.80)\n",
      "[17, 800] loss: 1.887 acc: (71.92)\n",
      "[18, 200] loss: 1.696 acc: (77.02)\n",
      "[18, 400] loss: 1.692 acc: (76.27)\n",
      "[18, 600] loss: 1.708 acc: (75.70)\n",
      "[18, 800] loss: 1.666 acc: (75.78)\n",
      "[19, 200] loss: 1.474 acc: (80.95)\n",
      "[19, 400] loss: 1.500 acc: (79.84)\n",
      "[19, 600] loss: 1.495 acc: (79.53)\n",
      "[19, 800] loss: 1.463 acc: (79.72)\n",
      "[20, 200] loss: 1.296 acc: (82.73)\n",
      "[20, 400] loss: 1.293 acc: (82.71)\n",
      "[20, 600] loss: 1.299 acc: (82.65)\n",
      "[20, 800] loss: 1.281 acc: (82.67)\n",
      "[21, 200] loss: 1.068 acc: (88.64)\n",
      "[21, 400] loss: 1.052 acc: (89.09)\n",
      "[21, 600] loss: 1.050 acc: (89.39)\n",
      "[21, 800] loss: 1.057 acc: (89.41)\n",
      "[22, 200] loss: 0.987 acc: (91.86)\n",
      "[22, 400] loss: 0.993 acc: (91.59)\n",
      "[22, 600] loss: 1.009 acc: (91.27)\n",
      "[22, 800] loss: 1.000 acc: (91.13)\n",
      "[23, 200] loss: 0.947 acc: (92.12)\n",
      "[23, 400] loss: 0.931 acc: (92.22)\n",
      "[23, 600] loss: 0.954 acc: (91.97)\n",
      "[23, 800] loss: 0.956 acc: (91.88)\n",
      "[24, 200] loss: 0.880 acc: (93.09)\n",
      "[24, 400] loss: 0.885 acc: (93.06)\n",
      "[24, 600] loss: 0.904 acc: (92.66)\n",
      "[24, 800] loss: 0.917 acc: (92.38)\n",
      "[25, 200] loss: 0.834 acc: (94.11)\n",
      "[25, 400] loss: 0.859 acc: (93.71)\n",
      "[25, 600] loss: 0.865 acc: (93.31)\n",
      "[25, 800] loss: 0.863 acc: (93.15)\n",
      "[26, 200] loss: 0.817 acc: (93.75)\n",
      "[26, 400] loss: 0.813 acc: (93.62)\n",
      "[26, 600] loss: 0.830 acc: (93.34)\n",
      "[26, 800] loss: 0.826 acc: (93.28)\n",
      "[27, 200] loss: 0.780 acc: (94.48)\n",
      "[27, 400] loss: 0.777 acc: (94.05)\n",
      "[27, 600] loss: 0.803 acc: (93.79)\n",
      "[27, 800] loss: 0.817 acc: (93.48)\n",
      "[28, 200] loss: 0.742 acc: (94.75)\n",
      "[28, 400] loss: 0.768 acc: (94.23)\n",
      "[28, 600] loss: 0.756 acc: (94.12)\n",
      "[28, 800] loss: 0.761 acc: (93.99)\n",
      "[29, 200] loss: 0.714 acc: (95.09)\n",
      "[29, 400] loss: 0.721 acc: (94.55)\n",
      "[29, 600] loss: 0.742 acc: (94.14)\n",
      "[29, 800] loss: 0.728 acc: (94.04)\n",
      "[30, 200] loss: 0.681 acc: (95.03)\n",
      "[30, 400] loss: 0.686 acc: (94.91)\n",
      "[30, 600] loss: 0.719 acc: (94.59)\n",
      "[30, 800] loss: 0.713 acc: (94.37)\n",
      "[31, 200] loss: 0.663 acc: (95.23)\n",
      "[31, 400] loss: 0.659 acc: (95.05)\n",
      "[31, 600] loss: 0.657 acc: (94.95)\n",
      "[31, 800] loss: 0.670 acc: (94.77)\n",
      "[32, 200] loss: 0.628 acc: (95.77)\n",
      "[32, 400] loss: 0.632 acc: (95.65)\n",
      "[32, 600] loss: 0.631 acc: (95.43)\n",
      "[32, 800] loss: 0.630 acc: (95.30)\n",
      "[33, 200] loss: 0.607 acc: (95.55)\n",
      "[33, 400] loss: 0.599 acc: (95.62)\n",
      "[33, 600] loss: 0.621 acc: (95.39)\n",
      "[33, 800] loss: 0.624 acc: (95.29)\n",
      "[34, 200] loss: 0.574 acc: (95.75)\n",
      "[34, 400] loss: 0.585 acc: (95.75)\n",
      "[34, 600] loss: 0.588 acc: (95.70)\n",
      "[34, 800] loss: 0.600 acc: (95.50)\n",
      "[35, 200] loss: 0.554 acc: (96.30)\n",
      "[35, 400] loss: 0.564 acc: (95.94)\n",
      "[35, 600] loss: 0.568 acc: (95.77)\n",
      "[35, 800] loss: 0.565 acc: (95.60)\n",
      "[36, 200] loss: 0.523 acc: (96.53)\n",
      "[36, 400] loss: 0.536 acc: (96.14)\n",
      "[36, 600] loss: 0.554 acc: (95.88)\n",
      "[36, 800] loss: 0.545 acc: (95.93)\n",
      "[37, 200] loss: 0.513 acc: (96.48)\n",
      "[37, 400] loss: 0.517 acc: (96.48)\n",
      "[37, 600] loss: 0.521 acc: (96.19)\n",
      "[37, 800] loss: 0.524 acc: (96.04)\n",
      "[38, 200] loss: 0.497 acc: (96.61)\n",
      "[38, 400] loss: 0.495 acc: (96.55)\n",
      "[38, 600] loss: 0.502 acc: (96.40)\n",
      "[38, 800] loss: 0.500 acc: (96.32)\n",
      "[39, 200] loss: 0.467 acc: (96.98)\n",
      "[39, 400] loss: 0.478 acc: (96.84)\n",
      "[39, 600] loss: 0.490 acc: (96.46)\n",
      "[39, 800] loss: 0.482 acc: (96.44)\n",
      "[40, 200] loss: 0.465 acc: (96.56)\n",
      "[40, 400] loss: 0.464 acc: (96.56)\n",
      "[40, 600] loss: 0.463 acc: (96.52)\n",
      "[40, 800] loss: 0.470 acc: (96.42)\n",
      "[41, 200] loss: 0.447 acc: (97.23)\n",
      "[41, 400] loss: 0.435 acc: (97.36)\n",
      "[41, 600] loss: 0.420 acc: (97.45)\n",
      "[41, 800] loss: 0.427 acc: (97.35)\n",
      "[42, 200] loss: 0.422 acc: (97.27)\n",
      "[42, 400] loss: 0.417 acc: (97.38)\n",
      "[42, 600] loss: 0.413 acc: (97.47)\n",
      "[42, 800] loss: 0.424 acc: (97.37)\n",
      "[43, 200] loss: 0.412 acc: (97.67)\n",
      "[43, 400] loss: 0.408 acc: (97.66)\n",
      "[43, 600] loss: 0.419 acc: (97.44)\n",
      "[43, 800] loss: 0.422 acc: (97.36)\n",
      "[44, 200] loss: 0.414 acc: (97.31)\n",
      "[44, 400] loss: 0.415 acc: (97.29)\n",
      "[44, 600] loss: 0.425 acc: (97.30)\n",
      "[44, 800] loss: 0.413 acc: (97.26)\n",
      "[45, 200] loss: 0.407 acc: (97.61)\n",
      "[45, 400] loss: 0.405 acc: (97.48)\n",
      "[45, 600] loss: 0.410 acc: (97.35)\n",
      "[45, 800] loss: 0.414 acc: (97.41)\n",
      "[46, 200] loss: 0.390 acc: (97.77)\n",
      "[46, 400] loss: 0.404 acc: (97.62)\n",
      "[46, 600] loss: 0.405 acc: (97.58)\n",
      "[46, 800] loss: 0.399 acc: (97.54)\n",
      "[47, 200] loss: 0.391 acc: (97.59)\n",
      "[47, 400] loss: 0.397 acc: (97.59)\n",
      "[47, 600] loss: 0.398 acc: (97.56)\n",
      "[47, 800] loss: 0.399 acc: (97.59)\n",
      "[48, 200] loss: 0.387 acc: (97.89)\n",
      "[48, 400] loss: 0.391 acc: (97.77)\n",
      "[48, 600] loss: 0.397 acc: (97.58)\n",
      "[48, 800] loss: 0.396 acc: (97.50)\n",
      "[49, 200] loss: 0.383 acc: (97.66)\n",
      "[49, 400] loss: 0.391 acc: (97.62)\n",
      "[49, 600] loss: 0.393 acc: (97.48)\n",
      "[49, 800] loss: 0.378 acc: (97.59)\n",
      "[50, 200] loss: 0.389 acc: (97.56)\n",
      "[50, 400] loss: 0.387 acc: (97.45)\n",
      "[50, 600] loss: 0.385 acc: (97.45)\n",
      "[50, 800] loss: 0.384 acc: (97.44)\n",
      "[51, 200] loss: 0.376 acc: (97.83)\n",
      "[51, 400] loss: 0.379 acc: (97.78)\n",
      "[51, 600] loss: 0.375 acc: (97.68)\n",
      "[51, 800] loss: 0.386 acc: (97.64)\n",
      "[52, 200] loss: 0.377 acc: (97.84)\n",
      "[52, 400] loss: 0.374 acc: (97.89)\n",
      "[52, 600] loss: 0.377 acc: (97.74)\n",
      "[52, 800] loss: 0.382 acc: (97.66)\n",
      "[53, 200] loss: 0.368 acc: (98.03)\n",
      "[53, 400] loss: 0.369 acc: (97.88)\n",
      "[53, 600] loss: 0.375 acc: (97.76)\n",
      "[53, 800] loss: 0.372 acc: (97.68)\n",
      "[54, 200] loss: 0.374 acc: (97.62)\n",
      "[54, 400] loss: 0.375 acc: (97.70)\n",
      "[54, 600] loss: 0.374 acc: (97.68)\n",
      "[54, 800] loss: 0.369 acc: (97.71)\n",
      "[55, 200] loss: 0.359 acc: (98.06)\n",
      "[55, 400] loss: 0.362 acc: (98.04)\n",
      "[55, 600] loss: 0.362 acc: (97.89)\n",
      "[55, 800] loss: 0.373 acc: (97.82)\n",
      "[56, 200] loss: 0.354 acc: (97.94)\n",
      "[56, 400] loss: 0.362 acc: (97.79)\n",
      "[56, 600] loss: 0.363 acc: (97.79)\n",
      "[56, 800] loss: 0.355 acc: (97.82)\n",
      "[57, 200] loss: 0.347 acc: (98.31)\n",
      "[57, 400] loss: 0.364 acc: (97.88)\n",
      "[57, 600] loss: 0.356 acc: (97.88)\n",
      "[57, 800] loss: 0.360 acc: (97.76)\n",
      "[58, 200] loss: 0.352 acc: (97.72)\n",
      "[58, 400] loss: 0.351 acc: (97.73)\n",
      "[58, 600] loss: 0.357 acc: (97.65)\n",
      "[58, 800] loss: 0.349 acc: (97.70)\n",
      "[59, 200] loss: 0.340 acc: (97.66)\n",
      "[59, 400] loss: 0.348 acc: (97.83)\n",
      "[59, 600] loss: 0.347 acc: (97.79)\n",
      "[59, 800] loss: 0.352 acc: (97.74)\n",
      "[60, 200] loss: 0.346 acc: (97.86)\n",
      "[60, 400] loss: 0.331 acc: (97.97)\n",
      "[60, 600] loss: 0.353 acc: (97.78)\n",
      "[60, 800] loss: 0.350 acc: (97.75)\n",
      "[61, 200] loss: 0.343 acc: (97.97)\n",
      "[61, 400] loss: 0.340 acc: (97.88)\n",
      "[61, 600] loss: 0.348 acc: (97.79)\n",
      "[61, 800] loss: 0.352 acc: (97.73)\n",
      "[62, 200] loss: 0.328 acc: (98.14)\n",
      "[62, 400] loss: 0.344 acc: (97.98)\n",
      "[62, 600] loss: 0.334 acc: (97.82)\n",
      "[62, 800] loss: 0.339 acc: (97.79)\n",
      "[63, 200] loss: 0.332 acc: (98.14)\n",
      "[63, 400] loss: 0.323 acc: (98.15)\n",
      "[63, 600] loss: 0.343 acc: (97.96)\n",
      "[63, 800] loss: 0.333 acc: (97.93)\n",
      "[64, 200] loss: 0.327 acc: (98.11)\n",
      "[64, 400] loss: 0.327 acc: (98.05)\n",
      "[64, 600] loss: 0.329 acc: (97.95)\n",
      "[64, 800] loss: 0.348 acc: (97.83)\n",
      "[65, 200] loss: 0.322 acc: (97.94)\n",
      "[65, 400] loss: 0.332 acc: (97.83)\n",
      "[65, 600] loss: 0.339 acc: (97.71)\n",
      "[65, 800] loss: 0.330 acc: (97.71)\n",
      "[66, 200] loss: 0.326 acc: (98.16)\n",
      "[66, 400] loss: 0.321 acc: (98.18)\n",
      "[66, 600] loss: 0.324 acc: (98.06)\n",
      "[66, 800] loss: 0.321 acc: (97.98)\n",
      "[67, 200] loss: 0.314 acc: (98.12)\n",
      "[67, 400] loss: 0.325 acc: (98.00)\n",
      "[67, 600] loss: 0.325 acc: (97.97)\n",
      "[67, 800] loss: 0.322 acc: (97.88)\n",
      "[68, 200] loss: 0.317 acc: (98.12)\n",
      "[68, 400] loss: 0.317 acc: (98.17)\n",
      "[68, 600] loss: 0.315 acc: (98.10)\n",
      "[68, 800] loss: 0.320 acc: (98.03)\n",
      "[69, 200] loss: 0.319 acc: (97.91)\n",
      "[69, 400] loss: 0.313 acc: (97.85)\n",
      "[69, 600] loss: 0.310 acc: (97.93)\n",
      "[69, 800] loss: 0.312 acc: (97.88)\n",
      "[70, 200] loss: 0.316 acc: (98.03)\n",
      "[70, 400] loss: 0.311 acc: (97.96)\n",
      "[70, 600] loss: 0.316 acc: (97.92)\n",
      "[70, 800] loss: 0.312 acc: (97.92)\n",
      "[71, 200] loss: 0.305 acc: (98.05)\n",
      "[71, 400] loss: 0.317 acc: (98.04)\n",
      "[71, 600] loss: 0.310 acc: (98.05)\n",
      "[71, 800] loss: 0.309 acc: (97.96)\n",
      "[72, 200] loss: 0.300 acc: (98.05)\n",
      "[72, 400] loss: 0.309 acc: (97.94)\n",
      "[72, 600] loss: 0.299 acc: (98.07)\n",
      "[72, 800] loss: 0.309 acc: (98.02)\n",
      "[73, 200] loss: 0.296 acc: (98.38)\n",
      "[73, 400] loss: 0.303 acc: (98.18)\n",
      "[73, 600] loss: 0.306 acc: (98.01)\n",
      "[73, 800] loss: 0.303 acc: (98.01)\n",
      "[74, 200] loss: 0.299 acc: (98.22)\n",
      "[74, 400] loss: 0.299 acc: (98.19)\n",
      "[74, 600] loss: 0.304 acc: (98.08)\n",
      "[74, 800] loss: 0.300 acc: (98.07)\n",
      "[75, 200] loss: 0.303 acc: (98.17)\n",
      "[75, 400] loss: 0.296 acc: (98.18)\n",
      "[75, 600] loss: 0.300 acc: (98.07)\n",
      "[75, 800] loss: 0.296 acc: (98.12)\n",
      "[76, 200] loss: 0.297 acc: (98.02)\n",
      "[76, 400] loss: 0.293 acc: (98.12)\n",
      "[76, 600] loss: 0.301 acc: (98.04)\n",
      "[76, 800] loss: 0.298 acc: (98.04)\n",
      "[77, 200] loss: 0.288 acc: (98.19)\n",
      "[77, 400] loss: 0.287 acc: (98.09)\n",
      "[77, 600] loss: 0.294 acc: (97.97)\n",
      "[77, 800] loss: 0.295 acc: (98.03)\n",
      "[78, 200] loss: 0.294 acc: (97.95)\n",
      "[78, 400] loss: 0.283 acc: (98.12)\n",
      "[78, 600] loss: 0.291 acc: (98.14)\n",
      "[78, 800] loss: 0.293 acc: (98.04)\n",
      "[79, 200] loss: 0.286 acc: (98.19)\n",
      "[79, 400] loss: 0.288 acc: (98.20)\n",
      "[79, 600] loss: 0.288 acc: (98.21)\n",
      "[79, 800] loss: 0.289 acc: (98.11)\n",
      "[80, 200] loss: 0.283 acc: (98.23)\n",
      "[80, 400] loss: 0.287 acc: (98.12)\n",
      "[80, 600] loss: 0.283 acc: (98.14)\n",
      "[80, 800] loss: 0.280 acc: (98.05)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 80\n",
    "SAVE_PATH = \"model/\"\n",
    "\n",
    "net.to(device)\n",
    "net.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    total = torch.tensor(0).to(device)\n",
    "    correct = torch.tensor(0).to(device)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        x, y = data\n",
    "        optimizer.zero_grad()\n",
    "        out = net(x.to(device))\n",
    "        loss = criterion(out, y.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred = torch.max(out.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (pred == y.to(device)).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        ratio = (correct / total).to(\"cpu\")\n",
    "        if i % 200 == 199:\n",
    "            print(f'[{epoch + 1}, {i + 1:3d}] loss: {running_loss / 199:.3f} acc: ({100*ratio:.2f})')\n",
    "            running_loss = 0.0\n",
    "    lr_scheduler.step()\n",
    "    torch.save(net.state_dict(), os.path.join(SAVE_PATH, \"model_classifier_256x128_e\" + str(epoch) + \"_\" + str(date.today()) + \".pth\"))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainevalloader = torch.utils.data.DataLoader(trainevalset, batch_size=256, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset acc: 98.94\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "net.to(device)\n",
    "with torch.no_grad():\n",
    "    total = torch.tensor(0).to(device)\n",
    "    correct = torch.tensor(0).to(device)\n",
    "    for i, data in enumerate(trainevalloader, 0):\n",
    "        x, y = data\n",
    "        out = net(x.to(device))\n",
    "        _, pred = torch.max(out.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (pred == y.to(device)).sum().item()\n",
    "acc = (correct / total * 100).to(\"cpu\")\n",
    "print(\"Trainset acc: %.2f\" %(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69cf509240d94a37c1094653e766edea7cfd00f05bbee75c76ffbfcae4e4ebc8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('torch_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
